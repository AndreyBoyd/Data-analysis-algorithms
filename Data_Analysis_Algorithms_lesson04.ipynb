{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 4. Алгоритм построения дерева решений\n",
    "\n",
    "#### 1. В коде из методички реализуйте один или несколько из критериев останова (количество листьев, количество используемых признаков, глубина дерева и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "classification_data, classification_labels = make_classification(n_samples=1000, n_features=2, n_informative=2, \n",
    "                                                                 n_classes=2, n_redundant=0,\n",
    "                                                                 n_clusters_per_class=1, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(classification_data, \n",
    "                                                                    classification_labels, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "            \n",
    "        # найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет критерия Джини\n",
    "\n",
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет прироста\n",
    "\n",
    "def gain(left_labels, right_labels, root_gini):\n",
    "\n",
    "    # доля выборки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return root_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение датасета в узле\n",
    "\n",
    "def split(data, labels, column_index, t):\n",
    "    \n",
    "    left = np.where(data[:, column_index] <= t)\n",
    "    right = np.where(data[:, column_index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    \n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_samples_leaf = 5\n",
    "\n",
    "    root_gini = gini(labels)\n",
    "\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # Проверяем только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_gain = gain(true_labels, false_labels, root_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    return best_gain, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree(data, labels):\n",
    "\n",
    "    gain, t, index = find_best_split(data, labels)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качестве\n",
    "    if gain == 0:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_labels)\n",
    "    false_branch = build_tree(false_data, false_labels)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напечатаем ход нашего дерева\n",
    "def print_tree(node, spacing=\"\"):\n",
    "\n",
    "    # Если лист, то выводим его прогноз\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Прогноз:\", node.prediction)\n",
    "        return\n",
    "\n",
    "    # Выведем значение индекса и порога на этом узле\n",
    "    print(spacing + 'Индекс', str(node.index), '<=', str(node.t))\n",
    "\n",
    "    # Рекурсионный вызов функции на положительном поддереве\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Рекурсионный вызов функции на отрицательном поддереве\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Введем функцию подсчета точности как доли правильных ответов\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 0 <= -0.001967524769128759\n",
      "--> True:\n",
      "  Индекс 1 <= -1.3993975578815423\n",
      "  --> True:\n",
      "    Индекс 1 <= -1.6646404646216442\n",
      "    --> True:\n",
      "      Индекс 0 <= -0.8728986138474495\n",
      "      --> True:\n",
      "        Прогноз: 0\n",
      "      --> False:\n",
      "        Прогноз: 0\n",
      "    --> False:\n",
      "      Индекс 0 <= -0.6882680999463433\n",
      "      --> True:\n",
      "        Прогноз: 0\n",
      "      --> False:\n",
      "        Индекс 0 <= -0.40118216125291906\n",
      "        --> True:\n",
      "          Индекс 1 <= -1.5684737117409848\n",
      "          --> True:\n",
      "            Индекс 0 <= -0.5543283463967666\n",
      "            --> True:\n",
      "              Прогноз: 1\n",
      "            --> False:\n",
      "              Прогноз: 1\n",
      "          --> False:\n",
      "            Прогноз: 0\n",
      "        --> False:\n",
      "          Индекс 1 <= -1.5264301097909836\n",
      "          --> True:\n",
      "            Прогноз: 1\n",
      "          --> False:\n",
      "            Индекс 1 <= -1.4255078037225668\n",
      "            --> True:\n",
      "              Прогноз: 1\n",
      "            --> False:\n",
      "              Прогноз: 1\n",
      "  --> False:\n",
      "    Прогноз: 0\n",
      "--> False:\n",
      "  Индекс 1 <= -1.4518330557811816\n",
      "  --> True:\n",
      "    Прогноз: 0\n",
      "  --> False:\n",
      "    Индекс 0 <= 0.08948763365897339\n",
      "    --> True:\n",
      "      Индекс 0 <= 0.04459943514365716\n",
      "      --> True:\n",
      "        Прогноз: 1\n",
      "      --> False:\n",
      "        Прогноз: 1\n",
      "    --> False:\n",
      "      Индекс 0 <= 1.2003150546431454\n",
      "      --> True:\n",
      "        Индекс 0 <= 1.1480251121818283\n",
      "        --> True:\n",
      "          Индекс 1 <= -1.0609167140093252\n",
      "          --> True:\n",
      "            Прогноз: 1\n",
      "          --> False:\n",
      "            Индекс 0 <= 0.8595014481629895\n",
      "            --> True:\n",
      "              Прогноз: 1\n",
      "            --> False:\n",
      "              Прогноз: 1\n",
      "        --> False:\n",
      "          Прогноз: 1\n",
      "      --> False:\n",
      "        Прогноз: 1\n"
     ]
    }
   ],
   "source": [
    "# Построим дерево по обучающей выборке\n",
    "my_tree = build_tree(train_data, train_labels)\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(my_tree):\n",
    "    train_answers = predict(train_data, my_tree)\n",
    "\n",
    "    train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "    print(train_accuracy)\n",
    "\n",
    "    answers = predict(test_data, my_tree)\n",
    "\n",
    "    test_accuracy = accuracy_metric(test_labels, answers)\n",
    "    print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.14285714285714\n",
      "95.0\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, labels, n_features):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_samples_leaf = 5\n",
    "\n",
    "    root_gini = gini(labels)\n",
    "\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_gain = gain(true_labels, false_labels, root_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    return best_gain, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "def build_tree(data, labels, n_features):\n",
    "    \n",
    "    gain, t, index = find_best_split(data, labels, n_features)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if gain == 0:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_labels, n_features)\n",
    "    false_branch = build_tree(false_data, false_labels, n_features)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим дерево по обучающей выборке\n",
    "my_tree = build_tree(train_data, train_labels, n_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ИЗМЕНЕНИЯ: дерево организуем тоже классом\n",
    "# Класс дерева\n",
    "\n",
    "class Tree:\n",
    "    \n",
    "    # ИЗМЕНЕНИЯ: здесь указаны параметры для останова\n",
    "    def __init__(self,\n",
    "                 max_tree_depth_stop=np.inf,\n",
    "                 max_leaf_num_stop=np.inf,\n",
    "                 min_leaf_object_stop=1):\n",
    "        self.max_depth = max_tree_depth_stop\n",
    "        self.nodes = []\n",
    "        self.leaves = []\n",
    "        self.depth = 0\n",
    "        self.max_leaves = max_leaf_num_stop\n",
    "        self.min_objects = min_leaf_object_stop\n",
    "        self.tree = None\n",
    "        \n",
    "    # Расчет критерия Джини\n",
    "    def gini(self,\n",
    "             labels):\n",
    "        #  подсчет количества объектов разных классов\n",
    "        classes = {}\n",
    "        for label in labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "\n",
    "        #  расчет критерия\n",
    "        impurity = 1\n",
    "        for label in classes:\n",
    "            p = classes[label] / len(labels)\n",
    "            impurity -= p ** 2\n",
    "\n",
    "        return impurity\n",
    "    \n",
    "    # Расчет прироста\n",
    "    def gain(self,\n",
    "             left_labels,\n",
    "             right_labels,\n",
    "             root_gini):\n",
    "\n",
    "        # доля выборки, ушедшая в левое поддерево\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "\n",
    "        return root_gini - p * self.gini(left_labels) - (1 - p) * self.gini(right_labels)\n",
    "    \n",
    "    # Разбиение датасета в узле\n",
    "    def split(self,\n",
    "              data,\n",
    "              labels,\n",
    "              column_index,\n",
    "              t):\n",
    "\n",
    "        left = np.where(data[:, column_index] <= t)\n",
    "        right = np.where(data[:, column_index] > t)\n",
    "\n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "\n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "    \n",
    "    # Нахождение наилучшего разбиения\n",
    "    def find_best_split(self,\n",
    "                        data,\n",
    "                        labels):\n",
    "\n",
    "        #  обозначим минимальное количество объектов в узле\n",
    "        min_samples_leaf = 5\n",
    "\n",
    "        root_gini = self.gini(labels)\n",
    "\n",
    "        best_gain = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "\n",
    "        n_features = data.shape[1]\n",
    "\n",
    "        for index in range(n_features):\n",
    "            # будем проверять только уникальные значения признака, исключая повторения\n",
    "            t_values = np.unique(data[:, index])\n",
    "\n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "                #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "                if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                    continue\n",
    "\n",
    "                current_gain = self.gain(true_labels, false_labels, root_gini)\n",
    "\n",
    "                #  выбираем порог, на котором получается максимальный прирост качества\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "        return best_gain, best_t, best_index\n",
    "    \n",
    "    # Построение дерева с помощью рекурсивной функции\n",
    "    def build_tree(self,\n",
    "                   data,\n",
    "                   labels):\n",
    "\n",
    "        gain, t, index = self.find_best_split(data, labels)\n",
    "    \n",
    "        #  Прекращаем рекурсию, когда достигли максимальной глубины дерева\n",
    "        if self.depth > self.max_depth:\n",
    "            self.leaves.append(Leaf(data, labels))\n",
    "            return Leaf(data, labels)\n",
    "        \n",
    "        \n",
    "         #  Прекращаем рекурсию, когда нет прироста в качества\n",
    "        if gain == 0:\n",
    "            self.leaves.append(Leaf(data, labels))\n",
    "            return Leaf(data, labels)\n",
    "\n",
    "        self.depth += 1\n",
    "        \n",
    "        true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "\n",
    "        # Рекурсивно строим два поддерева\n",
    "        true_branch = self.build_tree(true_data, true_labels)\n",
    "        false_branch = self.build_tree(false_data, false_labels)\n",
    "\n",
    "        # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "        self.nodes.append(Node(index, t, true_branch, false_branch))\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "    \n",
    "    def classify_object(self,\n",
    "                        obj,\n",
    "                        node):\n",
    "\n",
    "        #  Останавливаем рекурсию, если достигли листа\n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.t:\n",
    "            return self.classify_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self.classify_object(obj, node.false_branch)\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        self.tree = self.build_tree(data, labels)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "    \n",
    "        classes = []\n",
    "        for obj in data:\n",
    "            prediction = self.classify_object(obj, self.tree)\n",
    "            classes.append(prediction)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Реализуем критерий останова ГЛУБИНА ДЕРЕВА."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tree at 0x2b324635cd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Строим дерево с критерием останова глубина дерева \n",
    "tree_depth = Tree(max_tree_depth_stop=5) # ограничим глубину дерева\n",
    "tree_depth.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.85714285714286"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(train_labels, tree_depth.predict(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.66666666666667"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(test_labels, tree_depth.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 0 <= -0.001967524769128759\n",
      "--> True:\n",
      "  Индекс 1 <= -1.3993975578815423\n",
      "  --> True:\n",
      "    Индекс 1 <= -1.6646404646216442\n",
      "    --> True:\n",
      "      Индекс 0 <= -0.8728986138474495\n",
      "      --> True:\n",
      "        Прогноз: 0\n",
      "      --> False:\n",
      "        Прогноз: 0\n",
      "    --> False:\n",
      "      Индекс 0 <= -0.6882680999463433\n",
      "      --> True:\n",
      "        Прогноз: 0\n",
      "      --> False:\n",
      "        Индекс 0 <= -0.40118216125291906\n",
      "        --> True:\n",
      "          Прогноз: 0\n",
      "        --> False:\n",
      "          Прогноз: 1\n",
      "  --> False:\n",
      "    Прогноз: 0\n",
      "--> False:\n",
      "  Прогноз: 1\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree_depth.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Для задачи классификации обучить дерево решений с использованием критериев разбиения Джини и Энтропия. Сравнить качество классификации, сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "data, targets = make_regression(n_features=2, n_informative=2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_regr, test_data_regr, train_target_regr, test_target_regr = train_test_split(data, \n",
    "                                                                                        targets, \n",
    "                                                                                        test_size=0.3,\n",
    "                                                                                        random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf_clsf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "            \n",
    "        # найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction        \n",
    "    \n",
    "\n",
    "class Leaf_regr:\n",
    "    \n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.targets.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTree:\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth,\n",
    "                 max_leaf_nodes,\n",
    "                 min_leaf_samples,\n",
    "                 leaf_class):\n",
    "        self.max_depth = max_depth\n",
    "        self.nodes = []\n",
    "        self.leaves = []\n",
    "        self.depth = 0\n",
    "        self.max_leaves = max_leaf_nodes\n",
    "        self.min_objects = min_leaf_samples\n",
    "        self.tree = None\n",
    "        self.Leaf = leaf_class\n",
    "        \n",
    "    # Разбиение датасета в узле\n",
    "    def split(self,\n",
    "              data,\n",
    "              labels,\n",
    "              column_index,\n",
    "              t):\n",
    "\n",
    "        left = np.where(data[:, column_index] <= t)\n",
    "        right = np.where(data[:, column_index] > t)\n",
    "\n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "\n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "    \n",
    "    # Расчет прироста\n",
    "    def gain(self,\n",
    "             left_labels,\n",
    "             right_labels,\n",
    "             root):\n",
    "\n",
    "        # доля выборки, ушедшая в левое поддерево\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "\n",
    "        return root - p * self.criterion(left_labels) - (1 - p) * self.criterion(right_labels)   \n",
    "    \n",
    "    # Нахождение наилучшего разбиения\n",
    "    def find_best_split(self,\n",
    "                        data,\n",
    "                        labels):\n",
    "\n",
    "        #  обозначим минимальное количество объектов в узле\n",
    "        min_samples_leaf = 5\n",
    "\n",
    "        root = self.criterion(labels)\n",
    "\n",
    "        best_gain = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "\n",
    "        n_features = data.shape[1]\n",
    "\n",
    "        for index in range(n_features):\n",
    "            # будем проверять только уникальные значения признака, исключая повторения\n",
    "            t_values = np.unique(data[:, index])\n",
    "\n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "                #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "                if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                    continue\n",
    "\n",
    "                current_gain = self.gain(true_labels, false_labels, root)\n",
    "\n",
    "                #  выбираем порог, на котором получается максимальный прирост качества\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "        return best_gain, best_t, best_index\n",
    "    \n",
    "    # Построение дерева с помощью рекурсивной функции\n",
    "    def build_tree(self,\n",
    "                   data,\n",
    "                   labels):\n",
    "\n",
    "        gain, t, index = self.find_best_split(data, labels)\n",
    "        \n",
    "        #  Прекращаем рекурсию, когда достигли максимальной глубины дерева\n",
    "        if self.depth > self.max_depth:\n",
    "            self.leaves.append(self.Leaf(data, labels))\n",
    "            return self.Leaf(data, labels)\n",
    "        \n",
    "         #  Прекращаем рекурсию, когда нет прироста в качества\n",
    "        if gain == 0:\n",
    "            self.leaves.append(self.Leaf(data, labels))\n",
    "            return self.Leaf(data, labels)\n",
    "\n",
    "        self.depth += 1\n",
    "        \n",
    "        true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "\n",
    "        # Рекурсивно строим два поддерева\n",
    "        true_branch = self.build_tree(true_data, true_labels)\n",
    "        false_branch = self.build_tree(false_data, false_labels)\n",
    "\n",
    "        # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "        self.nodes.append(Node(index, t, true_branch, false_branch))\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "    \n",
    "    def predict_object(self,\n",
    "                       obj,\n",
    "                       node):\n",
    "\n",
    "        #  Останавливаем рекурсию, если достигли листа\n",
    "        if isinstance(node, self.Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.t:\n",
    "            return self.predict_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self.predict_object(obj, node.false_branch)\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        self.tree = self.build_tree(data, labels)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "    \n",
    "        classes = []\n",
    "        for obj in data:\n",
    "            prediction = self.predict_object(obj, self.tree)\n",
    "            classes.append(prediction)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_Tree(BaseTree):\n",
    "    def __init__(self,\n",
    "                 max_depth=np.inf,\n",
    "                 max_leaf_nodes=np.inf,\n",
    "                 min_leaf_samples=1,\n",
    "                 leaf_class=Leaf_clsf):\n",
    "        super().__init__(max_depth=max_depth,\n",
    "                         max_leaf_nodes=max_leaf_nodes,\n",
    "                         min_leaf_samples=min_leaf_samples,\n",
    "                         leaf_class=Leaf_clsf)\n",
    "\n",
    "    # Расчет критерия Джини\n",
    "    def criterion(self,\n",
    "                  labels):\n",
    "        #  подсчет количества объектов разных классов\n",
    "        classes = {}\n",
    "        for label in labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "\n",
    "        #  расчет критерия\n",
    "        impurity = 1\n",
    "        for label in classes:\n",
    "            p = classes[label] / len(labels)\n",
    "            impurity -= p ** 2\n",
    "\n",
    "        return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression_Tree(BaseTree):\n",
    "    def __init__(self,\n",
    "                 max_depth=np.inf,\n",
    "                 max_leaf_nodes=np.inf,\n",
    "                 min_leaf_samples=1,\n",
    "                 leaf_class=Leaf_regr):\n",
    "        super().__init__(max_depth=max_depth,\n",
    "                         max_leaf_nodes=max_leaf_nodes,\n",
    "                         min_leaf_samples=min_leaf_samples,\n",
    "                         leaf_class=Leaf_regr)\n",
    "\n",
    "    # Расчет дисперсии\n",
    "    def criterion(self, targets):\n",
    "        return np.mean((targets - targets.mean())**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Критерий разбиения Джини."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9185714285714286, 0.8566666666666667)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clsf = Classification_Tree(max_depth=5)\n",
    "clsf.fit(train_data, train_labels)\n",
    "\n",
    "accuracy_score(train_labels, clsf.predict(train_data)), accuracy_score(test_labels, clsf.predict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Критерий разбиения Энтропия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9159953829578108, 0.8071102270379656)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "regr = Regression_Tree(max_depth=5)\n",
    "regr.fit(train_data_regr, train_target_regr)\n",
    "\n",
    "r2_score(train_target_regr, regr.predict(train_data_regr)), r2_score(test_target_regr, regr.predict(test_data_regr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод: Результаты практически идентичные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 [опция]. Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем класс терминального узла на базе данных из задания 2 чтобы не плодить сущностей\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.targets.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(targets):\n",
    "    return np.mean((targets - targets.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, targets):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_samples_leaf = 5\n",
    "\n",
    "    root_mse = mse(targets)\n",
    "\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_targets, false_targets = split(data, targets, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_gain = gain(true_targets, false_targets, root_mse)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    return best_gain, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree(data, target):\n",
    "\n",
    "    gain, t, index = find_best_split(data, target)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if gain == 0:\n",
    "        return Leaf(data, target)\n",
    "\n",
    "    true_data, false_data, true_target, false_target = split(data, target, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_target)\n",
    "    false_branch = build_tree(false_data, false_target)\n",
    "\n",
    "    node = Node(index, t, true_branch, false_branch)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 0 <= -1.167278449710173\n",
      "--> True:\n",
      "  Прогноз: -121.39064849773837\n",
      "--> False:\n",
      "  Индекс 0 <= -0.8126247611063044\n",
      "  --> True:\n",
      "    Прогноз: -58.83807643952095\n",
      "  --> False:\n",
      "    Индекс 0 <= -0.5017555471945\n",
      "    --> True:\n",
      "      Прогноз: -50.68338930141631\n",
      "    --> False:\n",
      "      Индекс 0 <= -0.28143012121166766\n",
      "      --> True:\n",
      "        Прогноз: -19.53457742091028\n",
      "      --> False:\n",
      "        Индекс 0 <= 0.10134479014204936\n",
      "        --> True:\n",
      "          Индекс 0 <= -0.10593044205742323\n",
      "          --> True:\n",
      "            Прогноз: -19.179384142931184\n",
      "          --> False:\n",
      "            Прогноз: 11.007437547567205\n",
      "        --> False:\n",
      "          Индекс 0 <= 0.30364846530823975\n",
      "          --> True:\n",
      "            Прогноз: 17.82546436535075\n",
      "          --> False:\n",
      "            Индекс 0 <= 0.6178447508392777\n",
      "            --> True:\n",
      "              Индекс 0 <= 0.44295626086393586\n",
      "              --> True:\n",
      "                Прогноз: 32.35717501918585\n",
      "              --> False:\n",
      "                Прогноз: 44.73161236384692\n",
      "            --> False:\n",
      "              Индекс 0 <= 0.7769075911230111\n",
      "              --> True:\n",
      "                Прогноз: 49.38316175366546\n",
      "              --> False:\n",
      "                Индекс 0 <= 1.1522047703756748\n",
      "                --> True:\n",
      "                  Прогноз: 44.50582349952781\n",
      "                --> False:\n",
      "                  Прогноз: 113.00294879297327\n"
     ]
    }
   ],
   "source": [
    "# Построим дерево по обучающей выборке\n",
    "my_tree = build_tree(train_data_regr, train_target_regr)\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8994102006971118\n",
      "0.8047526472601623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "train_answers = predict(train_data_regr, my_tree)\n",
    "train_r2 = r2_score(train_target_regr, train_answers)\n",
    "print(train_r2)\n",
    "\n",
    "answers = predict(test_data_regr, my_tree)\n",
    "test_r2 = r2_score(test_target_regr, answers)\n",
    "print(test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9239432496382057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(train_data_regr, train_target_regr)\n",
    "\n",
    "train_answers = tree.predict(train_data_regr)\n",
    "train_r2 = r2_score(train_target_regr, train_answers)\n",
    "print(train_r2)\n",
    "\n",
    "answers = tree.predict(test_data_regr)\n",
    "test_r2 = r2_score(test_target_regr, answers)\n",
    "print(test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
